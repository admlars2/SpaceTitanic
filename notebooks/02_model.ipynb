{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db9cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e49b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # ---------- Group ----------\n",
    "    # PassengerId format: gggg_pp\n",
    "    group_str = df[\"PassengerId\"].astype(\"string\").str.split(\"_\").str[0]\n",
    "    df[\"GroupId\"] = pd.to_numeric(group_str, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Group size (computed within the provided df; do this on train+test concatenated if you want full info)\n",
    "    group_size = df.groupby(\"GroupId\")[\"PassengerId\"].transform(\"size\")\n",
    "    df[\"GroupSizeCapped\"] = group_size.clip(upper=6)\n",
    "    df[\"GroupSizeCapped\"] = df[\"GroupSizeCapped\"].astype(\"Int64\").fillna(-1)\n",
    "    df[\"IsGroupSize6Plus\"] = df[\"GroupSizeCapped\"].gt(5)\n",
    "\n",
    "    # ---------- Cabin ----------\n",
    "    cabin_parts = df[\"Cabin\"].astype(\"string\").str.split(\"/\", expand=True)\n",
    "\n",
    "    df[\"CabinDeck\"] = cabin_parts.get(0).astype(\"string\").fillna(\"Missing\")\n",
    "    df[\"CabinSide\"] = cabin_parts.get(2).astype(\"string\").fillna(\"Missing\")\n",
    "\n",
    "    cabin_num = pd.to_numeric(cabin_parts.get(1), errors=\"coerce\")\n",
    "    df[\"CabinNumMissing\"] = cabin_num.isna().astype(int)\n",
    "    df[\"CabinNum\"] = cabin_num.fillna(-1).astype(int)\n",
    "\n",
    "    # Bin CabinNum (keep -1 as its own bin label)\n",
    "    bin_size = 50\n",
    "    max_num = int(df.loc[df[\"CabinNum\"] >= 0, \"CabinNum\"].max()) if (df[\"CabinNum\"] >= 0).any() else 0\n",
    "    bins = np.arange(0, max_num + bin_size, bin_size)\n",
    "    df[\"CabinNum_bin\"] = pd.cut(\n",
    "        df[\"CabinNum\"].where(df[\"CabinNum\"] >= 0, np.nan),  # exclude -1 from numeric bins\n",
    "        bins=bins,\n",
    "        right=False,\n",
    "        include_lowest=True\n",
    "    ).astype(\"string\").fillna(\"Missing\")\n",
    "\n",
    "    # ---------- Categoricals ----------\n",
    "    df[\"HomePlanet\"] = df[\"HomePlanet\"].astype(\"string\").fillna(\"Missing\")\n",
    "    df[\"Destination\"] = df[\"Destination\"].astype(\"string\").fillna(\"Missing\")\n",
    "\n",
    "    # ---------- Booleans (treat as categorical with Missing) ----------\n",
    "    # Keep as strings to one-hot later; avoids int conversion issues\n",
    "    df[\"CryoSleep\"] = df[\"CryoSleep\"].astype(\"string\").fillna(\"Missing\")\n",
    "    df[\"VIP\"] = df[\"VIP\"].astype(\"string\").fillna(\"Missing\")\n",
    "\n",
    "    # ---------- Age ----------\n",
    "    df[\"AgeMissing\"] = df[\"Age\"].isna().astype(int)\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-1)  # or median, depending on model\n",
    "\n",
    "    # ---------- Expenses ----------\n",
    "    expense_cols = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "\n",
    "    df[\"SpendMissingCount\"] = df[expense_cols].isna().sum(axis=1).astype(int)\n",
    "\n",
    "    filled = df[expense_cols].fillna(0)\n",
    "    df[\"NumAmenitiesUsed\"] = filled.gt(0).sum(axis=1).astype(int)\n",
    "    df[\"TotalExpenses\"] = filled.sum(axis=1)\n",
    "\n",
    "    df[\"NoSpend\"] = (df[\"TotalExpenses\"] == 0).astype(int)\n",
    "    df[\"TotalExpenses_log\"] = np.log1p(df[\"TotalExpenses\"])\n",
    "\n",
    "    # Return only model features + GroupId for GroupKFold\n",
    "    keep = [\n",
    "        \"CryoSleep\", \"HomePlanet\", \"Destination\",\n",
    "        \"CabinDeck\", \"CabinSide\", \"CabinNum_bin\",\n",
    "        \"Age\", \"AgeMissing\",\n",
    "        \"VIP\",\n",
    "        \"GroupSizeCapped\", \"IsGroupSize6Plus\", \"GroupId\",\n",
    "        \"NoSpend\", \"SpendMissingCount\", \"NumAmenitiesUsed\", \"TotalExpenses_log\",\n",
    "    ]\n",
    "    return df[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1df9e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CryoSleep            string[python]\n",
       "HomePlanet           string[python]\n",
       "Destination          string[python]\n",
       "CabinDeck            string[python]\n",
       "CabinSide            string[python]\n",
       "CabinNum_bin         string[python]\n",
       "Age                         float64\n",
       "AgeMissing                    int64\n",
       "VIP                  string[python]\n",
       "GroupSizeCapped               Int64\n",
       "IsGroupSize6Plus            boolean\n",
       "GroupId                       Int64\n",
       "NoSpend                       int64\n",
       "SpendMissingCount             int64\n",
       "NumAmenitiesUsed              int64\n",
       "TotalExpenses_log           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_project_root(start: Path | None = None) -> Path:\n",
    "    \"\"\"Walk upward until we find pyproject.toml (repo root).\"\"\"\n",
    "    start = start or Path.cwd()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"pyproject.toml\").exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "PROJECT_DIR = find_project_root()\n",
    "DATA_DIR = PROJECT_DIR / \"data\"\n",
    "\n",
    "train_path = DATA_DIR / \"train.csv\"\n",
    "test_path = DATA_DIR / \"test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "train_df_features = make_features(train_df)\n",
    "test_df_features = make_features(test_df)\n",
    "\n",
    "train_df_features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=12, micro=3, releaselevel='final', serial=0)\n",
      "Train model on 6954 examples\n",
      "Model trained in 0:00:00.576070\n",
      "Fold 1/5 accuracy: 0.73260\n",
      "Train model on 6954 examples\n",
      "Model trained in 0:00:00.257271\n",
      "Fold 2/5 accuracy: 0.76366\n",
      "Train model on 6954 examples\n",
      "Model trained in 0:00:00.252833\n",
      "Fold 3/5 accuracy: 0.76136\n",
      "Train model on 6955 examples\n",
      "Model trained in 0:00:00.244784\n",
      "Fold 4/5 accuracy: 0.73475\n",
      "Train model on 6955 examples\n",
      "Model trained in 0:00:00.256195\n",
      "Fold 5/5 accuracy: 0.75316\n",
      "Mean CV accuracy: 0.74911 ± 0.01309\n",
      "Train model on 8693 examples\n",
      "Model trained in 0:00:00.359397\n",
      "Wrote: /mnt/c/Users/atric/GitHub/SpaceTitanic/submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01        False\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01        False\n",
       "4     0023_01        False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- YDF CV (GroupKFold) + final training + submission ---\n",
    "\n",
    "# YDF setup\n",
    "# Note: TF-DF and TF itself can be platform/version picky; YDF is the successor library.\n",
    "\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import ydf\n",
    "except ModuleNotFoundError as e:\n",
    "    raise RuntimeError(\n",
    "        \"YDF is not installed. In WSL: poetry install --with tfdf (which brings ydf)\"\n",
    "    ) from e\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_SPLITS = 5\n",
    "\n",
    "# Labels\n",
    "y = train_df[\"Transported\"].astype(int)\n",
    "\n",
    "# Groups (do NOT feed to model)\n",
    "groups = train_df_features[\"GroupId\"]\n",
    "\n",
    "# Features (keep GroupId for splitting only)\n",
    "X_all = train_df_features\n",
    "\n",
    "fold_accs: list[float] = []\n",
    "\n",
    "gkf = GroupKFold(n_splits=N_SPLITS)\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X_all, y, groups=groups), start=1):\n",
    "    X_train = X_all.iloc[train_idx].drop(columns=[\"GroupId\"])\n",
    "    X_val = X_all.iloc[val_idx].drop(columns=[\"GroupId\"])\n",
    "\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val = y.iloc[val_idx]\n",
    "\n",
    "    train_fold_df = X_train.assign(Transported=y_train)\n",
    "    val_fold_df = X_val.assign(Transported=y_val)\n",
    "\n",
    "    model = ydf.GradientBoostedTreesLearner(\n",
    "        label=\"Transported\",\n",
    "        task=ydf.Task.CLASSIFICATION,\n",
    "        random_seed=RANDOM_SEED,\n",
    "    ).train(train_fold_df)\n",
    "\n",
    "    # YDF outputs probabilities for the positive class in binary classification\n",
    "    pred = model.predict(val_fold_df.drop(columns=[\"Transported\"]))\n",
    "    pred_label = (pred >= 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val.to_numpy(), pred_label)\n",
    "    fold_accs.append(acc)\n",
    "    print(f\"Fold {fold}/{N_SPLITS} accuracy: {acc:.5f}\")\n",
    "\n",
    "print(f\"Mean CV accuracy: {np.mean(fold_accs):.5f} ± {np.std(fold_accs):.5f}\")\n",
    "\n",
    "# --- Train final model on all rows ---\n",
    "X_train_full = train_df_features.drop(columns=[\"GroupId\"]).copy()\n",
    "train_full_df = X_train_full.assign(Transported=y)\n",
    "\n",
    "final_model = ydf.GradientBoostedTreesLearner(\n",
    "    label=\"Transported\",\n",
    "    task=ydf.Task.CLASSIFICATION,\n",
    "    random_seed=RANDOM_SEED,\n",
    ").train(train_full_df)\n",
    "\n",
    "# --- Predict test + write submission ---\n",
    "X_test = test_df_features.drop(columns=[\"GroupId\"]).copy()\n",
    "\n",
    "test_pred = final_model.predict(X_test)\n",
    "test_label = (test_pred >= 0.5)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_df[\"PassengerId\"],\n",
    "    \"Transported\": test_label,\n",
    "})\n",
    "\n",
    "out_path = PROJECT_DIR / \"submission.csv\"\n",
    "submission.to_csv(out_path, index=False)\n",
    "print(f\"Wrote: {out_path}\")\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpaceTitanic (WSL GPU)",
   "language": "python",
   "name": "spacetitanic-wsl-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
